{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04f27a3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-cdaabf834096>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-cdaabf834096>\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    Read datasets\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "Read datasets\n",
    "fake = pd.read_csv(\"data/Fake.csv\")\n",
    "true = pd.read_csv(\"data/True.csv\")\n",
    "fake.shape\n",
    "(23481, 4)\n",
    "true.shape\n",
    "(21417, 4)\n",
    "Data cleaning and preparation\n",
    "# Add flag to track fake and real\n",
    "fake['target'] = 'fake'\n",
    "true['target'] = 'true'\n",
    "# Concatenate dataframes\n",
    "data = pd.concat([fake, true]).reset_index(drop = True)\n",
    "data.shape\n",
    "(44898, 5)\n",
    "# Shuffle the data\n",
    "from sklearn.utils import shuffle\n",
    "data = shuffle(data)\n",
    "data = data.reset_index(drop=True)\n",
    "# Check the data\n",
    "data.head()\n",
    "title\ttext\tsubject\tdate\ttarget\n",
    "0\tPortuguese ex-PM Socrates indicted on corrupti...\tLISBON (Reuters) - Former Portuguese prime min...\tworldnews\tOctober 11, 2017\ttrue\n",
    "1\tBoiler Room EP #113 – ‘CNN is ISIS’\tTune in to the Alternate Current Radio Network...\tMiddle-east\tJune 16, 2017\tfake\n",
    "2\tHILLARY GOT DESTROYED By Chris Wallace On FOX ...\tHillary shouldn t be on FOX News giving interv...\tleft-news\tAug 3, 2016\tfake\n",
    "3\tTrump recommits to U.S. allies but says they m...\tWASHINGTON (Reuters) - President Donald Trump ...\tpoliticsNews\tMarch 1, 2017\ttrue\n",
    "4\tOAS says Honduran vote results in doubt due to...\tTEGUCIGALPA (Reuters) - Observers cannot be ce...\tworldnews\tDecember 4, 2017\ttrue\n",
    "# Removing the date (we won't use it for the analysis)\n",
    "data.drop([\"date\"],axis=1,inplace=True)\n",
    "data.head()\n",
    "title\ttext\tsubject\ttarget\n",
    "0\tTrump uses policy speech to attack media, prom...\tGETTSYBURG, Pa. (Reuters) - U.S. Republican pr...\tpoliticsNews\ttrue\n",
    "1\tLiz Cheney's Wyoming campaign backed by big na...\tCODY, Wyo. (Reuters) - Former Vice President D...\tpoliticsNews\ttrue\n",
    "2\tTogolese to vote on presidential term limits a...\tLOME (Reuters) - A bill to limit presidents in...\tworldnews\ttrue\n",
    "3\tHillary Clinton says U.S. threats of war with ...\tSEOUL (Reuters) - Former U.S. presidential can...\tpoliticsNews\ttrue\n",
    "4\tTrump administration, world financial official...\tWASHINGTON (Reuters) - The Trump administratio...\tpoliticsNews\ttrue\n",
    "# Removing the title (we will only use the text)\n",
    "data.drop([\"title\"],axis=1,inplace=True)\n",
    "data.head()\n",
    "text\tsubject\ttarget\n",
    "0\tGETTSYBURG, Pa. (Reuters) - U.S. Republican pr...\tpoliticsNews\ttrue\n",
    "1\tCODY, Wyo. (Reuters) - Former Vice President D...\tpoliticsNews\ttrue\n",
    "2\tLOME (Reuters) - A bill to limit presidents in...\tworldnews\ttrue\n",
    "3\tSEOUL (Reuters) - Former U.S. presidential can...\tpoliticsNews\ttrue\n",
    "4\tWASHINGTON (Reuters) - The Trump administratio...\tpoliticsNews\ttrue\n",
    "# Convert to lowercase\n",
    "\n",
    "data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "data.head()\n",
    "text\tsubject\ttarget\n",
    "0\tgettsyburg, pa. (reuters) - u.s. republican pr...\tpoliticsNews\ttrue\n",
    "1\tcody, wyo. (reuters) - former vice president d...\tpoliticsNews\ttrue\n",
    "2\tlome (reuters) - a bill to limit presidents in...\tworldnews\ttrue\n",
    "3\tseoul (reuters) - former u.s. presidential can...\tpoliticsNews\ttrue\n",
    "4\twashington (reuters) - the trump administratio...\tpoliticsNews\ttrue\n",
    "# Remove punctuation\n",
    "\n",
    "import string\n",
    "\n",
    "def punctuation_removal(text):\n",
    "    all_list = [char for char in text if char not in string.punctuation]\n",
    "    clean_str = ''.join(all_list)\n",
    "    return clean_str\n",
    "\n",
    "data['text'] = data['text'].apply(punctuation_removal)\n",
    "# Check\n",
    "data.head()\n",
    "text\tsubject\ttarget\n",
    "0\tgettsyburg pa reuters us republican president...\tpoliticsNews\ttrue\n",
    "1\tcody wyo reuters former vice president dick c...\tpoliticsNews\ttrue\n",
    "2\tlome reuters a bill to limit presidents in to...\tworldnews\ttrue\n",
    "3\tseoul reuters former us presidential candidat...\tpoliticsNews\ttrue\n",
    "4\twashington reuters the trump administration h...\tpoliticsNews\ttrue\n",
    "# Removing stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "data['text'] = data['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "[nltk_data] Downloading package stopwords to\n",
    "[nltk_data]     /Users/faviovazquez/nltk_data...\n",
    "[nltk_data]   Package stopwords is already up-to-date!\n",
    "data.head()\n",
    "text\tsubject\ttarget\n",
    "0\tgettsyburg pa reuters us republican presidenti...\tpoliticsNews\ttrue\n",
    "1\tcody wyo reuters former vice president dick ch...\tpoliticsNews\ttrue\n",
    "2\tlome reuters bill limit presidents togo two te...\tworldnews\ttrue\n",
    "3\tseoul reuters former us presidential candidate...\tpoliticsNews\ttrue\n",
    "4\twashington reuters trump administration simple...\tpoliticsNews\ttrue\n",
    "Basic data exploration\n",
    "# How many articles per subject?\n",
    "print(data.groupby(['subject'])['text'].count())\n",
    "data.groupby(['subject'])['text'].count().plot(kind=\"bar\")\n",
    "plt.show()\n",
    "subject\n",
    "Government News     1570\n",
    "Middle-east          778\n",
    "News                9050\n",
    "US_News              783\n",
    "left-news           4459\n",
    "politics            6841\n",
    "politicsNews       11272\n",
    "worldnews          10145\n",
    "Name: text, dtype: int64\n",
    "\n",
    "# How many fake and real articles?\n",
    "print(data.groupby(['target'])['text'].count())\n",
    "data.groupby(['target'])['text'].count().plot(kind=\"bar\")\n",
    "plt.show()\n",
    "target\n",
    "fake    23481\n",
    "true    21417\n",
    "Name: text, dtype: int64\n",
    "\n",
    "# Word cloud for fake news\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "fake_data = data[data[\"target\"] == \"fake\"]\n",
    "all_words = ' '.join([text for text in fake_data.text])\n",
    "\n",
    "wordcloud = WordCloud(width= 800, height= 500,\n",
    "                          max_font_size = 110,\n",
    "                          collocations = False).generate(all_words)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Word cloud for real news\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "real_data = data[data[\"target\"] == \"true\"]\n",
    "all_words = ' '.join([text for text in fake_data.text])\n",
    "\n",
    "wordcloud = WordCloud(width= 800, height= 500,\n",
    "                          max_font_size = 110,\n",
    "                          collocations = False).generate(all_words)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Most frequent words counter (Code adapted from https://www.kaggle.com/rodolfoluna/fake-news-detector)   \n",
    "from nltk import tokenize\n",
    "\n",
    "token_space = tokenize.WhitespaceTokenizer()\n",
    "\n",
    "def counter(text, column_text, quantity):\n",
    "    all_words = ' '.join([text for text in text[column_text]])\n",
    "    token_phrase = token_space.tokenize(all_words)\n",
    "    frequency = nltk.FreqDist(token_phrase)\n",
    "    df_frequency = pd.DataFrame({\"Word\": list(frequency.keys()),\n",
    "                                   \"Frequency\": list(frequency.values())})\n",
    "    df_frequency = df_frequency.nlargest(columns = \"Frequency\", n = quantity)\n",
    "    plt.figure(figsize=(12,8))\n",
    "    ax = sns.barplot(data = df_frequency, x = \"Word\", y = \"Frequency\", color = 'blue')\n",
    "    ax.set(ylabel = \"Count\")\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.show()\n",
    "# Most frequent words in fake news\n",
    "counter(data[data[\"target\"] == \"fake\"], \"text\", 20)\n",
    "\n",
    "# Most frequent words in real news\n",
    "counter(data[data[\"target\"] == \"true\"], \"text\", 20)\n",
    "\n",
    "Modeling\n",
    "# Function to plot the confusion matrix (code from https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html)\n",
    "from sklearn import metrics\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "Peparing the data\n",
    "# Split the data\n",
    "X_train,X_test,y_train,y_test = train_test_split(data['text'], data.target, test_size=0.2, random_state=42)\n",
    "Logistic regression\n",
    "# Vectorizing and applying TF-IDF\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('model', LogisticRegression())])\n",
    "\n",
    "# Fitting the model\n",
    "model = pipe.fit(X_train, y_train)\n",
    "\n",
    "# Accuracy\n",
    "prediction = model.predict(X_test)\n",
    "print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))\n",
    "accuracy: 98.76%\n",
    "cm = metrics.confusion_matrix(y_test, prediction)\n",
    "plot_confusion_matrix(cm, classes=['Fake', 'Real'])\n",
    "Confusion matrix, without normalization\n",
    "\n",
    "Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Vectorizing and applying TF-IDF\n",
    "pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('model', DecisionTreeClassifier(criterion= 'entropy',\n",
    "                                           max_depth = 20, \n",
    "                                           splitter='best', \n",
    "                                           random_state=42))])\n",
    "# Fitting the model\n",
    "model = pipe.fit(X_train, y_train)\n",
    "\n",
    "# Accuracy\n",
    "prediction = model.predict(X_test)\n",
    "print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))\n",
    "accuracy: 99.71%\n",
    "cm = metrics.confusion_matrix(y_test, prediction)\n",
    "plot_confusion_matrix(cm, classes=['Fake', 'Real'])\n",
    "Confusion matrix, without normalization\n",
    "\n",
    "Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('model', RandomForestClassifier(n_estimators=50, criterion=\"entropy\"))])\n",
    "\n",
    "model = pipe.fit(X_train, y_train)\n",
    "prediction = model.predict(X_test)\n",
    "print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))\n",
    "accuracy: 98.98%\n",
    "cm = metrics.confusion_matrix(y_test, prediction)\n",
    "plot_confusion_matrix(cm, classes=['Fake', 'Real'])\n",
    "Confusion matrix, without normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04d268b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
